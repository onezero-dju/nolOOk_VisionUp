import streamlit as st
from fastapi import FastAPI, UploadFile, File
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from collections import Counter
import os
import re

app = FastAPI()

# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(".cache/files", exist_ok=True)

@app.post("/upload-markdown/")
async def upload_markdown(file: UploadFile = File(...)):
    content = await file.read()
    text = content.decode("utf-8")
    # íŒŒì¼ ì €ì¥
    file_path = f"./.cache/files/{file.filename}"
    with open(file_path, "w") as f:
        f.write(text)
    return {"filename": file.filename, "message": "File uploaded successfully"}

# í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(text, num_keywords=5):
    # ë¹„ë¬¸ì ì œê±° ë° ì†Œë¬¸ìë¡œ ë³€í™˜
    words = re.findall(r'\b\w+\b', text.lower())
    count = Counter(words)
    keywords = count.most_common(num_keywords)
    return keywords

st.set_page_config(page_title="Markdown íŒŒì¼ í‚¤ì›Œë“œ ì¶”ì¶œ", page_icon="ğŸ“„")
st.title("Markdown íŒŒì¼ í‚¤ì›Œë“œ ì¶”ì¶œ")

uploaded_file = st.file_uploader("Markdown íŒŒì¼ ì—…ë¡œë“œ", type=["md"])
if uploaded_file:
    content = uploaded_file.getvalue().decode("utf-8")
    keywords = extract_keywords(content)
    st.subheader("ì¶”ì¶œëœ í‚¤ì›Œë“œ:")
    st.write([word for word, _ in keywords])
    st.subheader("ê°€ì¥ ë§ì´ ë‚˜ì˜¨ í‚¤ì›Œë“œ:")
    st.write(keywords[0][0] if keywords else "No keywords found")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)